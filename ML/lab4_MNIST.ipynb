{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ca67e86",
   "metadata": {},
   "source": [
    "lab4_MNIST\n",
    "\n",
    "Решить задачу классификации датасета MNIST используя MLP из scikitlearn и используя CNN (по типу LeNet) c пакетом PyTorch.\n",
    "\n",
    "Сравнить результаты по метрикам, сделать обоснованные выводы\n",
    "\n",
    "\n"
   ],
   "attachments": {
    "83fc4bac-ae64-4b86-bfbe-2549eb0f1265.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAA9CAIAAAB3OhciAAAAdUlEQVR4Xu3BgQAAAADDoPlTX+EAVQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADcBnsqAAG+YqPTAAAAAElFTkSuQmCC"
    },
    "b1adc725-57d2-4579-9725-99d0c05882f5.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAA9CAIAAAB3OhciAAAAdUlEQVR4Xu3BgQAAAADDoPlTX+EAVQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADcBnsqAAG+YqPTAAAAAElFTkSuQmCC"
    },
    "76883a60-e802-4ef3-a775-59f746c80157.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAA9CAIAAAB3OhciAAAAdUlEQVR4Xu3BgQAAAADDoPlTX+EAVQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADcBnsqAAG+YqPTAAAAAElFTkSuQmCC"
    },
    "dba9bcb7-e281-4769-94a2-14138392e212.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAA9CAIAAAB3OhciAAAAdUlEQVR4Xu3BgQAAAADDoPlTX+EAVQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADcBnsqAAG+YqPTAAAAAElFTkSuQmCC"
    }
   }
  },
  {
   "cell_type": "code",
   "id": "f1c33876",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T18:00:58.796575Z",
     "start_time": "2025-12-23T18:00:57.705328Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "np.random.seed(42)\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "b5d380be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T18:01:09.796600Z",
     "start_time": "2025-12-23T18:00:58.801883Z"
    }
   },
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml(\"mnist_784\", version=1, as_frame=False)\n",
    "X = mnist.data.astype(np.float32) / 255.0\n",
    "y = mnist.target.astype(np.int64)\n",
    "\n",
    "# стандартное разбиение MNIST: 60k train, 10k test\n",
    "X_train, X_test = X[:60000], X[60000:]\n",
    "y_train, y_test = y[:60000], y[60000:]\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784), (60000,), (10000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "ca375a42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T18:01:10.001047Z",
     "start_time": "2025-12-23T18:01:09.808057Z"
    }
   },
   "source": [
    "# Визуализация примеров\n",
    "fig, axes = plt.subplots(1, 6, figsize=(12, 2.5))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(X_train[i].reshape(28, 28), cmap=\"gray\")\n",
    "    ax.set_title(str(y_train[i]))\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x250 with 6 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "0e671879",
   "metadata": {},
   "source": [
    "### Заключение по визуализации данных\n",
    "\n",
    "Визуализация примеров изображений из обучающей выборки подтверждает корректность загрузки датасета MNIST. Изображения цифр хорошо различимы, классы соответствуют ожидаемым значениям, что указывает на отсутствие ошибок в процессе загрузки и предобработки данных.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57771da1",
   "metadata": {},
   "source": [
    "Используем `MLPClassifier`. Для MNIST важно:\n",
    "- нормализация/стандартизация входа (добавим `StandardScaler`);\n",
    "- `early_stopping=True` чтобы не переобучаться и не ждать слишком долго;\n",
    "- разумная архитектура (256, 128) как baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "0b37dcc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T18:01:21.396459Z",
     "start_time": "2025-12-23T18:01:10.008559Z"
    }
   },
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "mlp = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", MLPClassifier(\n",
    "        hidden_layer_sizes=(256, 128),\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        batch_size=256,\n",
    "        learning_rate_init=1e-3,\n",
    "        max_iter=20,\n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=3,\n",
    "        verbose=True,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "\n",
    "acc_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "prec_mlp, rec_mlp, f1_mlp, _ = precision_recall_fscore_support(y_test, y_pred_mlp, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(\"MLP (sklearn) metrics:\")\n",
    "print(\"Accuracy:\", acc_mlp)\n",
    "print(\"Precision_macro:\", prec_mlp)\n",
    "print(\"Recall_macro:\", rec_mlp)\n",
    "print(\"F1_macro:\", f1_mlp)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.29334085\n",
      "Validation score: 0.956500\n",
      "Iteration 2, loss = 0.09863696\n",
      "Validation score: 0.962000\n",
      "Iteration 3, loss = 0.05893268\n",
      "Validation score: 0.967167\n",
      "Iteration 4, loss = 0.03920817\n",
      "Validation score: 0.965667\n",
      "Iteration 5, loss = 0.02465275\n",
      "Validation score: 0.968333\n",
      "Iteration 6, loss = 0.01658263\n",
      "Validation score: 0.969333\n",
      "Iteration 7, loss = 0.01431763\n",
      "Validation score: 0.971333\n",
      "Iteration 8, loss = 0.01074474\n",
      "Validation score: 0.966667\n",
      "Iteration 9, loss = 0.01612496\n",
      "Validation score: 0.966833\n",
      "Iteration 10, loss = 0.01845096\n",
      "Validation score: 0.963167\n",
      "Iteration 11, loss = 0.02066228\n",
      "Validation score: 0.964500\n",
      "Validation score did not improve more than tol=0.000100 for 3 consecutive epochs. Stopping.\n",
      "MLP (sklearn) metrics:\n",
      "Accuracy: 0.9752\n",
      "Precision_macro: 0.9749455868171824\n",
      "Recall_macro: 0.9750258103036582\n",
      "F1_macro: 0.9749728600079015\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "14ec9330",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T18:01:21.427643Z",
     "start_time": "2025-12-23T18:01:21.402974Z"
    }
   },
   "source": [
    "# Матрица ошибок и отчет (MLP)\n",
    "cm_mlp = confusion_matrix(y_test, y_pred_mlp)\n",
    "print(\"Confusion matrix (MLP):\\n\", cm_mlp)\n",
    "\n",
    "print(\"\\nClassification report (MLP):\")\n",
    "print(classification_report(y_test, y_pred_mlp, digits=4))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (MLP):\n",
      " [[ 970    0    0    1    1    1    2    1    3    1]\n",
      " [   0 1125    3    2    0    1    2    1    1    0]\n",
      " [   6    2  999    2    3    1    6    7    6    0]\n",
      " [   0    0    4  984    0    8    2    3    3    6]\n",
      " [   0    0    3    3  957    1    5    4    1    8]\n",
      " [   3    0    0    6    1  869    5    0    5    3]\n",
      " [   4    3    2    1    3    2  941    0    2    0]\n",
      " [   0    3    7    2    0    1    0 1000    4   11]\n",
      " [   4    0    2   10    7    8    2    3  933    5]\n",
      " [   2    2    0    7    6    4    0   10    4  974]]\n",
      "\n",
      "Classification report (MLP):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9808    0.9898    0.9853       980\n",
      "           1     0.9912    0.9912    0.9912      1135\n",
      "           2     0.9794    0.9680    0.9737      1032\n",
      "           3     0.9666    0.9743    0.9704      1010\n",
      "           4     0.9785    0.9745    0.9765       982\n",
      "           5     0.9699    0.9742    0.9720       892\n",
      "           6     0.9751    0.9823    0.9787       958\n",
      "           7     0.9718    0.9728    0.9723      1028\n",
      "           8     0.9699    0.9579    0.9638       974\n",
      "           9     0.9663    0.9653    0.9658      1009\n",
      "\n",
      "    accuracy                         0.9752     10000\n",
      "   macro avg     0.9749    0.9750    0.9750     10000\n",
      "weighted avg     0.9752    0.9752    0.9752     10000\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "9f7a7cb5",
   "metadata": {},
   "source": [
    "CNN LeNet (PyTorch)\n",
    "\n",
    "Архитектура LeNet (адаптация под 28×28):\n",
    "- Conv(1→6, 5×5) → ReLU → AvgPool(2×2)\n",
    "- Conv(6→16, 5×5) → ReLU → AvgPool(2×2)\n",
    "- FC(16·4·4→120) → ReLU → FC(120→84) → ReLU → FC(84→10)\n",
    "\n",
    "Обучение: CrossEntropyLoss + Adam.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "94e4a23b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T18:01:23.852780Z",
     "start_time": "2025-12-23T18:01:21.432660Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "a785e67e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T18:01:33.822053Z",
     "start_time": "2025-12-23T18:01:23.860722Z"
    }
   },
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_ds = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_ds  = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=256, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "len(train_loader), len(test_loader)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:04<00:00, 2.02MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 246kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.27MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.27MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(469, 40)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Заключение по архитектуре CNN (LeNet)\n",
    "\n",
    "Используемая сверточная нейронная сеть основана на архитектуре LeNet и включает два сверточных слоя с последующим pooling, а также три полносвязных слоя. Такая архитектура позволяет эффективно извлекать локальные признаки изображений, такие как штрихи и контуры, что особенно важно для задач распознавания рукописных цифр.\n"
   ],
   "id": "8c22e48c"
  },
  {
   "cell_type": "code",
   "id": "01aeebd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T18:01:33.853584Z",
     "start_time": "2025-12-23T18:01:33.839070Z"
    }
   },
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)   # 28->24\n",
    "        self.pool  = nn.AvgPool2d(2, 2)               # 24->12\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)  # 12->8\n",
    "        # pool: 8->4\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "cnn = LeNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=1e-3)\n",
    "\n",
    "cnn\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "b0bd009c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T18:01:59.491879Z",
     "start_time": "2025-12-23T18:01:33.861097Z"
    }
   },
   "source": [
    "def train_one_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_model(model, loader):\n",
    "    model.eval()\n",
    "    all_true, all_pred = [], []\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        logits = model(xb)\n",
    "        pred = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        all_pred.append(pred)\n",
    "        all_true.append(yb.numpy())\n",
    "    return np.concatenate(all_true), np.concatenate(all_pred)\n",
    "\n",
    "EPOCHS = 3  # при GPU можно поставить 5-10\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    loss = train_one_epoch(cnn, train_loader)\n",
    "    y_true_cnn, y_pred_cnn = eval_model(cnn, test_loader)\n",
    "    acc = accuracy_score(y_true_cnn, y_pred_cnn)\n",
    "    print(f\"Epoch {epoch}/{EPOCHS} | loss={loss:.4f} | test_acc={acc:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Firo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | loss=0.5544 | test_acc=0.9352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Firo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | loss=0.1727 | test_acc=0.9647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Firo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | loss=0.1103 | test_acc=0.9743\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "acf1fd47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T18:01:59.522982Z",
     "start_time": "2025-12-23T18:01:59.506295Z"
    }
   },
   "source": [
    "acc_cnn = accuracy_score(y_true_cnn, y_pred_cnn)\n",
    "prec_cnn, rec_cnn, f1_cnn, _ = precision_recall_fscore_support(y_true_cnn, y_pred_cnn, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(\"CNN (LeNet) metrics:\")\n",
    "print(\"Accuracy:\", acc_cnn)\n",
    "print(\"Precision_macro:\", prec_cnn)\n",
    "print(\"Recall_macro:\", rec_cnn)\n",
    "print(\"F1_macro:\", f1_cnn)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN (LeNet) metrics:\n",
      "Accuracy: 0.9743\n",
      "Precision_macro: 0.9740067713258906\n",
      "Recall_macro: 0.9742689819231861\n",
      "F1_macro: 0.9740718599760985\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "62c77fe8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T18:01:59.554202Z",
     "start_time": "2025-12-23T18:01:59.535210Z"
    }
   },
   "source": [
    "cm_cnn = confusion_matrix(y_true_cnn, y_pred_cnn)\n",
    "print(\"Confusion matrix (CNN):\\n\", cm_cnn)\n",
    "\n",
    "print(\"\\nClassification report (CNN):\")\n",
    "print(classification_report(y_true_cnn, y_pred_cnn, digits=4))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (CNN):\n",
      " [[ 963    0    1    0    1    3    4    1    5    2]\n",
      " [   0 1125    1    2    0    2    2    0    3    0]\n",
      " [   4    3  998    6    1    2    2    7    9    0]\n",
      " [   0    0    3  971    0   17    0    6    7    6]\n",
      " [   0    0    2    0  966    0    5    2    0    7]\n",
      " [   2    1    0    6    0  876    3    1    1    2]\n",
      " [   5    3    0    0    4   10  932    0    4    0]\n",
      " [   1    6    9    4    2    0    0  991    4   11]\n",
      " [   2    0    0    2    4    6    2    1  952    5]\n",
      " [   0    7    0    2   19    9    0    3    0  969]]\n",
      "\n",
      "Classification report (CNN):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9857    0.9827    0.9842       980\n",
      "           1     0.9825    0.9912    0.9868      1135\n",
      "           2     0.9842    0.9671    0.9756      1032\n",
      "           3     0.9778    0.9614    0.9695      1010\n",
      "           4     0.9689    0.9837    0.9763       982\n",
      "           5     0.9470    0.9821    0.9642       892\n",
      "           6     0.9811    0.9729    0.9769       958\n",
      "           7     0.9792    0.9640    0.9716      1028\n",
      "           8     0.9665    0.9774    0.9719       974\n",
      "           9     0.9671    0.9604    0.9637      1009\n",
      "\n",
      "    accuracy                         0.9743     10000\n",
      "   macro avg     0.9740    0.9743    0.9741     10000\n",
      "weighted avg     0.9744    0.9743    0.9743     10000\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "04d440a3",
   "metadata": {},
   "source": [
    "## Сравнение результатов и выводы\n",
    "\n",
    "### Почему CNN обычно лучше на MNIST\n",
    "- MLP работает с вектором из 784 признаков и **не учитывает геометрию** изображения.\n",
    "- CNN (LeNet) использует **свёртки**, которые извлекают локальные признаки (штрихи, углы, контуры), и pooling, повышающий устойчивость к небольшим сдвигам.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "ff70b672",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T18:01:59.569703Z",
     "start_time": "2025-12-23T18:01:59.560646Z"
    }
   },
   "source": [
    "results = {\n",
    "    \"MLP_sklearn\": {\"accuracy\": float(acc_mlp), \"precision_macro\": float(prec_mlp), \"recall_macro\": float(rec_mlp), \"f1_macro\": float(f1_mlp)},\n",
    "    \"CNN_LeNet\":   {\"accuracy\": float(acc_cnn), \"precision_macro\": float(prec_cnn), \"recall_macro\": float(rec_cnn), \"f1_macro\": float(f1_cnn)},\n",
    "}\n",
    "results\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MLP_sklearn': {'accuracy': 0.9752,\n",
       "  'precision_macro': 0.9749455868171824,\n",
       "  'recall_macro': 0.9750258103036582,\n",
       "  'f1_macro': 0.9749728600079015},\n",
       " 'CNN_LeNet': {'accuracy': 0.9743,\n",
       "  'precision_macro': 0.9740067713258906,\n",
       "  'recall_macro': 0.9742689819231861,\n",
       "  'f1_macro': 0.9740718599760985}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
